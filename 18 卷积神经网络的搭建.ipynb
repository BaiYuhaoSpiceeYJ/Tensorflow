{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.727801\n",
      "0.15\n",
      "1 0.42530435\n",
      "2 0.3384133\n",
      "3 0.35763735\n",
      "4 0.38302475\n",
      "5 0.37854943\n",
      "6 0.3603\n",
      "7 0.34996805\n",
      "8 0.3453765\n",
      "9 0.34481463\n",
      "10 0.34402245\n",
      "11 0.33804312\n",
      "12 0.3439949\n",
      "13 0.33690542\n",
      "14 0.33366284\n",
      "15 0.3293373\n",
      "16 0.32944846\n",
      "17 0.33011702\n",
      "18 0.32700247\n",
      "19 0.32927775\n",
      "20 0.33178884\n",
      "21 0.33322126\n",
      "22 0.32992196\n",
      "23 0.33243045\n",
      "24 0.3293614\n",
      "25 0.33031684\n",
      "26 0.33135873\n",
      "27 0.32778454\n",
      "28 0.32723168\n",
      "29 0.3262879\n",
      "30 0.32488436\n",
      "31 0.32766095\n",
      "32 0.3260027\n",
      "33 0.3276744\n",
      "34 0.32784864\n",
      "35 0.32560557\n",
      "36 0.32582775\n",
      "37 0.32773328\n",
      "38 0.3261251\n",
      "39 0.3269537\n",
      "40 0.3230862\n",
      "41 0.32652703\n",
      "42 0.32542115\n",
      "43 0.3233245\n",
      "44 0.32564515\n",
      "45 0.32276988\n",
      "46 0.3237415\n",
      "47 0.32237226\n",
      "48 0.32458833\n",
      "49 0.32245463\n",
      "50 0.32598618\n",
      "0.13\n",
      "51 0.3262863\n",
      "52 0.327913\n",
      "53 0.32359743\n",
      "54 0.3255423\n",
      "55 0.3233173\n",
      "56 0.32340285\n",
      "57 0.32777578\n",
      "58 0.32643366\n",
      "59 0.32302198\n",
      "60 0.32381886\n",
      "61 0.32134503\n",
      "62 0.32373136\n",
      "63 0.32565144\n",
      "64 0.32183146\n",
      "65 0.3204492\n",
      "66 0.32220456\n",
      "67 0.3205306\n",
      "68 0.32432827\n",
      "69 0.3253492\n",
      "70 0.32192492\n",
      "71 0.32185498\n",
      "72 0.320391\n",
      "73 0.32097855\n",
      "74 0.3215483\n",
      "75 0.32268015\n",
      "76 0.32235375\n",
      "77 0.3216846\n",
      "78 0.323434\n",
      "79 0.32065812\n",
      "80 0.3213684\n",
      "81 0.31702772\n",
      "82 0.3168655\n",
      "83 0.32034522\n",
      "84 0.32181576\n",
      "85 0.32166043\n",
      "86 0.32500252\n",
      "87 0.32028678\n",
      "88 0.32118893\n",
      "89 0.321263\n",
      "90 0.31543344\n",
      "91 0.31658626\n",
      "92 0.31853756\n",
      "93 0.31677622\n",
      "94 0.31573823\n",
      "95 0.32348266\n",
      "96 0.3171121\n",
      "97 0.3190726\n",
      "98 0.3182239\n",
      "99 0.3178881\n",
      "100 0.31851298\n",
      "0.18\n",
      "101 0.31781444\n",
      "102 0.31852165\n",
      "103 0.3151036\n",
      "104 0.3184536\n",
      "105 0.31488284\n",
      "106 0.3145821\n",
      "107 0.31676796\n",
      "108 0.31660652\n",
      "109 0.3157546\n",
      "110 0.31409362\n",
      "111 0.31359395\n",
      "112 0.31683224\n",
      "113 0.3156489\n",
      "114 0.31381708\n",
      "115 0.31732965\n",
      "116 0.31174046\n",
      "117 0.3134497\n",
      "118 0.3138721\n",
      "119 0.31165186\n",
      "120 0.31204954\n",
      "121 0.30834907\n",
      "122 0.31461865\n",
      "123 0.31782797\n",
      "124 0.31358874\n",
      "125 0.31409436\n",
      "126 0.3137924\n",
      "127 0.30829543\n",
      "128 0.31007415\n",
      "129 0.30867875\n",
      "130 0.30909127\n",
      "131 0.30657834\n",
      "132 0.30695444\n",
      "133 0.30772322\n",
      "134 0.302219\n",
      "135 0.3056365\n",
      "136 0.31230336\n",
      "137 0.3095197\n",
      "138 0.31056166\n",
      "139 0.30751592\n",
      "140 0.30871892\n",
      "141 0.30672663\n",
      "142 0.30490685\n",
      "143 0.3031064\n",
      "144 0.30783516\n",
      "145 0.3038393\n",
      "146 0.3051269\n",
      "147 0.3062234\n",
      "148 0.30303428\n",
      "149 0.3069719\n",
      "150 0.3045736\n",
      "0.235\n",
      "151 0.31097323\n",
      "152 0.30873376\n",
      "153 0.3131436\n",
      "154 0.30053055\n",
      "155 0.298804\n",
      "156 0.30854225\n",
      "157 0.30106804\n",
      "158 0.30216917\n",
      "159 0.30086097\n",
      "160 0.30063877\n",
      "161 0.30719894\n",
      "162 0.30365816\n",
      "163 0.2986843\n",
      "164 0.30808145\n",
      "165 0.30190533\n",
      "166 0.304377\n",
      "167 0.30041537\n",
      "168 0.29970723\n",
      "169 0.30146092\n",
      "170 0.30091745\n",
      "171 0.30311885\n",
      "172 0.29856476\n",
      "173 0.30110094\n",
      "174 0.2980942\n",
      "175 0.2958952\n",
      "176 0.29906866\n",
      "177 0.29102394\n",
      "178 0.29224643\n",
      "179 0.29688764\n",
      "180 0.2954798\n",
      "181 0.29880795\n",
      "182 0.29264182\n",
      "183 0.2955795\n",
      "184 0.29377526\n",
      "185 0.29117772\n",
      "186 0.30326876\n",
      "187 0.295215\n",
      "188 0.29369834\n",
      "189 0.29544103\n",
      "190 0.28615507\n",
      "191 0.29501653\n",
      "192 0.2928699\n",
      "193 0.29946652\n",
      "194 0.2889251\n",
      "195 0.29756758\n",
      "196 0.28733712\n",
      "197 0.29577515\n",
      "198 0.29616338\n",
      "199 0.29286927\n",
      "200 0.29040188\n",
      "0.35\n",
      "201 0.28876454\n",
      "202 0.29516506\n",
      "203 0.29387143\n",
      "204 0.2897032\n",
      "205 0.30306453\n",
      "206 0.2902674\n",
      "207 0.28806254\n",
      "208 0.2857961\n",
      "209 0.29010975\n",
      "210 0.28667754\n",
      "211 0.29232752\n",
      "212 0.29230458\n",
      "213 0.28246608\n",
      "214 0.28588647\n",
      "215 0.2906656\n",
      "216 0.28992924\n",
      "217 0.2906926\n",
      "218 0.2858693\n",
      "219 0.2851099\n",
      "220 0.28528708\n",
      "221 0.2849576\n",
      "222 0.2832883\n",
      "223 0.28413495\n",
      "224 0.28985426\n",
      "225 0.28368938\n",
      "226 0.28739998\n",
      "227 0.27852458\n",
      "228 0.28592676\n",
      "229 0.2851432\n",
      "230 0.282302\n",
      "231 0.27707997\n",
      "232 0.28392386\n",
      "233 0.28879088\n",
      "234 0.28058964\n",
      "235 0.28040776\n",
      "236 0.2868901\n",
      "237 0.27665988\n",
      "238 0.28335148\n",
      "239 0.28091663\n",
      "240 0.27548066\n",
      "241 0.28647608\n",
      "242 0.28770396\n",
      "243 0.27239472\n",
      "244 0.2828017\n",
      "245 0.28301945\n",
      "246 0.28440124\n",
      "247 0.26979622\n",
      "248 0.2829164\n",
      "249 0.28763002\n",
      "250 0.28510195\n",
      "0.37\n",
      "251 0.27774844\n",
      "252 0.27567953\n",
      "253 0.28115907\n",
      "254 0.27666178\n",
      "255 0.28422397\n",
      "256 0.27872384\n",
      "257 0.28803742\n",
      "258 0.28312746\n",
      "259 0.278111\n",
      "260 0.2750922\n",
      "261 0.27971745\n",
      "262 0.27936858\n",
      "263 0.28426665\n",
      "264 0.28668308\n",
      "265 0.27439293\n",
      "266 0.27308697\n",
      "267 0.27071095\n",
      "268 0.28237933\n",
      "269 0.29018635\n",
      "270 0.27979738\n",
      "271 0.27521497\n",
      "272 0.27539024\n",
      "273 0.27261892\n",
      "274 0.26295978\n",
      "275 0.2833814\n",
      "276 0.27929696\n",
      "277 0.270921\n",
      "278 0.27815044\n",
      "279 0.2690019\n",
      "280 0.26886123\n",
      "281 0.28643316\n",
      "282 0.2743774\n",
      "283 0.2725889\n",
      "284 0.26891717\n",
      "285 0.28138977\n",
      "286 0.2768075\n",
      "287 0.2798704\n",
      "288 0.27098778\n",
      "289 0.27317685\n",
      "290 0.27545577\n",
      "291 0.27110973\n",
      "292 0.28211656\n",
      "293 0.27682403\n",
      "294 0.2745795\n",
      "295 0.269781\n",
      "296 0.27521923\n",
      "297 0.2642554\n",
      "298 0.27076554\n",
      "299 0.28467077\n",
      "300 0.27356836\n",
      "0.325\n",
      "301 0.26402152\n",
      "302 0.2659634\n",
      "303 0.27197692\n",
      "304 0.27826917\n",
      "305 0.27088135\n",
      "306 0.28005427\n",
      "307 0.27650648\n",
      "308 0.28040284\n",
      "309 0.28390646\n",
      "310 0.2723805\n",
      "311 0.26570642\n",
      "312 0.27310738\n",
      "313 0.2716303\n",
      "314 0.2752199\n",
      "315 0.2711165\n",
      "316 0.26759225\n",
      "317 0.27072722\n",
      "318 0.2664724\n",
      "319 0.27435866\n",
      "320 0.26810843\n",
      "321 0.2819062\n",
      "322 0.2750507\n",
      "323 0.26690763\n",
      "324 0.2591659\n",
      "325 0.27658176\n",
      "326 0.2805071\n",
      "327 0.2734442\n",
      "328 0.2682115\n",
      "329 0.25833553\n",
      "330 0.26853994\n",
      "331 0.27822408\n",
      "332 0.26181388\n",
      "333 0.26021165\n",
      "334 0.265027\n",
      "335 0.2696495\n",
      "336 0.2624677\n",
      "337 0.26841712\n",
      "338 0.26985455\n",
      "339 0.26192752\n",
      "340 0.25993508\n",
      "341 0.27011028\n",
      "342 0.27099043\n",
      "343 0.2601331\n",
      "344 0.26059347\n",
      "345 0.2715842\n",
      "346 0.27080154\n",
      "347 0.2582975\n",
      "348 0.2673849\n",
      "349 0.2685725\n",
      "350 0.25903144\n",
      "0.37\n",
      "351 0.27149802\n",
      "352 0.26185572\n",
      "353 0.26357037\n",
      "354 0.27156574\n",
      "355 0.2552486\n",
      "356 0.25985175\n",
      "357 0.26887423\n",
      "358 0.26850095\n",
      "359 0.25669146\n",
      "360 0.26841083\n",
      "361 0.26321572\n",
      "362 0.2567106\n",
      "363 0.2695927\n",
      "364 0.26481825\n",
      "365 0.2651167\n",
      "366 0.25422847\n",
      "367 0.26472893\n",
      "368 0.26529473\n",
      "369 0.26728064\n",
      "370 0.26259822\n",
      "371 0.25132573\n",
      "372 0.256531\n",
      "373 0.25944796\n",
      "374 0.2665305\n",
      "375 0.26847768\n",
      "376 0.26232108\n",
      "377 0.2654871\n",
      "378 0.25923002\n",
      "379 0.26625767\n",
      "380 0.25770968\n",
      "381 0.24795315\n",
      "382 0.26955697\n",
      "383 0.27566856\n",
      "384 0.2705556\n",
      "385 0.25839162\n",
      "386 0.26423973\n",
      "387 0.26078987\n",
      "388 0.26389033\n",
      "389 0.26215157\n",
      "390 0.27024293\n",
      "391 0.2533744\n",
      "392 0.26582795\n",
      "393 0.2739119\n",
      "394 0.26023635\n",
      "395 0.25822702\n",
      "396 0.2634254\n",
      "397 0.25560352\n",
      "398 0.25949496\n",
      "399 0.25342196\n",
      "400 0.25131997\n",
      "0.445\n",
      "401 0.2621643\n",
      "402 0.2728311\n",
      "403 0.2656275\n",
      "404 0.27005875\n",
      "405 0.26438504\n",
      "406 0.24962464\n",
      "407 0.26161402\n",
      "408 0.2693167\n",
      "409 0.26101127\n",
      "410 0.264746\n",
      "411 0.25518435\n",
      "412 0.26149666\n",
      "413 0.260145\n",
      "414 0.25942907\n",
      "415 0.25344533\n",
      "416 0.24598917\n",
      "417 0.26914126\n",
      "418 0.26150388\n",
      "419 0.2754781\n",
      "420 0.2637256\n",
      "421 0.26444077\n",
      "422 0.25789753\n",
      "423 0.2691893\n",
      "424 0.26021513\n",
      "425 0.2506494\n",
      "426 0.25215876\n",
      "427 0.27387142\n",
      "428 0.2401053\n",
      "429 0.26561737\n",
      "430 0.27270383\n",
      "431 0.2568081\n",
      "432 0.2600647\n",
      "433 0.25955665\n",
      "434 0.24281664\n",
      "435 0.25657463\n",
      "436 0.25240415\n",
      "437 0.251966\n",
      "438 0.25942945\n",
      "439 0.24997774\n",
      "440 0.26742202\n",
      "441 0.25681737\n",
      "442 0.27219677\n",
      "443 0.27887148\n",
      "444 0.2592402\n",
      "445 0.25425565\n",
      "446 0.26591128\n",
      "447 0.25784492\n",
      "448 0.2589499\n",
      "449 0.2576397\n",
      "450 0.2609696\n",
      "0.405\n",
      "451 0.27078828\n",
      "452 0.2614877\n",
      "453 0.26825804\n",
      "454 0.253002\n",
      "455 0.25057483\n",
      "456 0.25385243\n",
      "457 0.25356203\n",
      "458 0.25454965\n",
      "459 0.26208633\n",
      "460 0.25300348\n",
      "461 0.26525354\n",
      "462 0.25850654\n",
      "463 0.25825492\n",
      "464 0.26288638\n",
      "465 0.2675336\n",
      "466 0.26531073\n",
      "467 0.25456282\n",
      "468 0.25807524\n",
      "469 0.25819436\n",
      "470 0.2640663\n",
      "471 0.26075897\n",
      "472 0.25731763\n",
      "473 0.26851544\n",
      "474 0.24983773\n",
      "475 0.2556623\n",
      "476 0.25248575\n",
      "477 0.25866228\n",
      "478 0.26747045\n",
      "479 0.24836197\n",
      "480 0.24816377\n",
      "481 0.25980672\n",
      "482 0.26441535\n",
      "483 0.24417384\n",
      "484 0.25005442\n",
      "485 0.26937103\n",
      "486 0.25823313\n",
      "487 0.28146094\n",
      "488 0.25798354\n",
      "489 0.2682067\n",
      "490 0.25950998\n",
      "491 0.24641232\n",
      "492 0.25899503\n",
      "493 0.25136375\n",
      "494 0.2654588\n",
      "495 0.25853258\n",
      "496 0.24722616\n",
      "497 0.263223\n",
      "498 0.26307723\n",
      "499 0.25639486\n",
      "500 0.257519\n",
      "0.465\n",
      "501 0.25215086\n",
      "502 0.25200963\n",
      "503 0.25578913\n",
      "504 0.25681683\n",
      "505 0.26057124\n",
      "506 0.24642448\n",
      "507 0.24421239\n",
      "508 0.26070943\n",
      "509 0.25900832\n",
      "510 0.25235078\n",
      "511 0.23720002\n",
      "512 0.25541836\n",
      "513 0.25249362\n",
      "514 0.2546627\n",
      "515 0.24877492\n",
      "516 0.25801182\n",
      "517 0.25414824\n",
      "518 0.2482051\n",
      "519 0.25400472\n",
      "520 0.25353467\n",
      "521 0.2525921\n",
      "522 0.26663122\n",
      "523 0.248949\n",
      "524 0.24381718\n",
      "525 0.2465343\n",
      "526 0.25377032\n",
      "527 0.2597472\n",
      "528 0.24364606\n",
      "529 0.2517783\n",
      "530 0.25596198\n",
      "531 0.23605902\n",
      "532 0.2528639\n",
      "533 0.25919664\n",
      "534 0.27049923\n",
      "535 0.26130563\n",
      "536 0.24765308\n",
      "537 0.25633657\n",
      "538 0.2502582\n",
      "539 0.25982833\n",
      "540 0.24823666\n",
      "541 0.24078378\n",
      "542 0.2466946\n",
      "543 0.25505295\n",
      "544 0.24883878\n",
      "545 0.24943236\n",
      "546 0.25565347\n",
      "547 0.24973822\n",
      "548 0.24621943\n",
      "549 0.24702582\n",
      "550 0.24636316\n",
      "0.425\n",
      "551 0.24615188\n",
      "552 0.24732718\n",
      "553 0.2482835\n",
      "554 0.24907711\n",
      "555 0.24738804\n",
      "556 0.25385723\n",
      "557 0.25457302\n",
      "558 0.27001226\n",
      "559 0.24628314\n",
      "560 0.26563805\n",
      "561 0.2477897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 0.24807315\n",
      "563 0.24984343\n",
      "564 0.24585967\n",
      "565 0.26456413\n",
      "566 0.24991925\n",
      "567 0.24619272\n",
      "568 0.26594836\n",
      "569 0.26005825\n",
      "570 0.24849734\n",
      "571 0.25041658\n",
      "572 0.24837372\n",
      "573 0.25355375\n",
      "574 0.25782385\n",
      "575 0.24845442\n",
      "576 0.24964003\n",
      "577 0.25590342\n",
      "578 0.24411964\n",
      "579 0.23968573\n",
      "580 0.23702757\n",
      "581 0.24165031\n",
      "582 0.23765321\n",
      "583 0.25948977\n",
      "584 0.25826973\n",
      "585 0.23669195\n",
      "586 0.24094729\n",
      "587 0.2552197\n",
      "588 0.24654892\n",
      "589 0.25514883\n",
      "590 0.24208388\n",
      "591 0.24058516\n",
      "592 0.24575749\n",
      "593 0.25998205\n",
      "594 0.2468262\n",
      "595 0.24564996\n",
      "596 0.2425712\n",
      "597 0.23881026\n",
      "598 0.23979643\n",
      "599 0.25579718\n",
      "600 0.24034627\n",
      "0.43\n",
      "601 0.25535142\n",
      "602 0.25623944\n",
      "603 0.24862532\n",
      "604 0.25070137\n",
      "605 0.24941358\n",
      "606 0.23766363\n",
      "607 0.24273007\n",
      "608 0.23721854\n",
      "609 0.25661477\n",
      "610 0.2646664\n",
      "611 0.23664758\n",
      "612 0.24321583\n",
      "613 0.24129629\n",
      "614 0.2422221\n",
      "615 0.23697853\n",
      "616 0.2565084\n",
      "617 0.24502175\n",
      "618 0.24705772\n",
      "619 0.24590854\n",
      "620 0.25207865\n",
      "621 0.24592546\n",
      "622 0.2422804\n",
      "623 0.24200244\n",
      "624 0.24883814\n",
      "625 0.24859324\n",
      "626 0.24280913\n",
      "627 0.24453345\n",
      "628 0.24648662\n",
      "629 0.24636921\n",
      "630 0.24911276\n",
      "631 0.25051314\n",
      "632 0.25778022\n",
      "633 0.25316483\n",
      "634 0.25379714\n",
      "635 0.2503819\n",
      "636 0.24858907\n",
      "637 0.2392805\n",
      "638 0.25029343\n",
      "639 0.2439045\n",
      "640 0.23438075\n",
      "641 0.24377152\n",
      "642 0.24679033\n",
      "643 0.23340607\n",
      "644 0.24833989\n",
      "645 0.24517274\n",
      "646 0.25294122\n",
      "647 0.2479339\n",
      "648 0.2395484\n",
      "649 0.24295893\n",
      "650 0.24269864\n",
      "0.38\n",
      "651 0.24849014\n",
      "652 0.23596843\n",
      "653 0.23623137\n",
      "654 0.24052095\n",
      "655 0.24162221\n",
      "656 0.25302333\n",
      "657 0.23377843\n",
      "658 0.24324977\n",
      "659 0.25284222\n",
      "660 0.24982595\n",
      "661 0.23667066\n",
      "662 0.25784424\n",
      "663 0.2287968\n",
      "664 0.25366548\n",
      "665 0.24422157\n",
      "666 0.26653793\n",
      "667 0.2540506\n",
      "668 0.2410088\n",
      "669 0.24950092\n",
      "670 0.23677644\n",
      "671 0.24128635\n",
      "672 0.25077942\n",
      "673 0.25296912\n",
      "674 0.2410036\n",
      "675 0.2456202\n",
      "676 0.24501196\n",
      "677 0.23573665\n",
      "678 0.24887785\n",
      "679 0.24386442\n",
      "680 0.246093\n",
      "681 0.24600673\n",
      "682 0.24929503\n",
      "683 0.23830529\n",
      "684 0.24468474\n",
      "685 0.2557788\n",
      "686 0.24559805\n",
      "687 0.23043828\n",
      "688 0.2466537\n",
      "689 0.24281025\n",
      "690 0.22895527\n",
      "691 0.24219593\n",
      "692 0.2338231\n",
      "693 0.2458153\n",
      "694 0.24552453\n",
      "695 0.24334057\n",
      "696 0.2483372\n",
      "697 0.24478228\n",
      "698 0.24192266\n",
      "699 0.24951215\n",
      "700 0.24490657\n",
      "0.46\n",
      "701 0.25725326\n",
      "702 0.248396\n",
      "703 0.24891067\n",
      "704 0.25260034\n",
      "705 0.24121293\n",
      "706 0.2506872\n",
      "707 0.23046923\n",
      "708 0.25480103\n",
      "709 0.23373494\n",
      "710 0.23285122\n",
      "711 0.25332385\n",
      "712 0.23883896\n",
      "713 0.25145754\n",
      "714 0.24651965\n",
      "715 0.24885592\n",
      "716 0.24932413\n",
      "717 0.2533722\n",
      "718 0.2621549\n",
      "719 0.24599068\n",
      "720 0.24067652\n",
      "721 0.23345704\n",
      "722 0.24956112\n",
      "723 0.24801831\n",
      "724 0.2501405\n",
      "725 0.24947262\n",
      "726 0.2355793\n",
      "727 0.24166599\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-60f69056af23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m#训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-60f69056af23>\u001b[0m in \u001b[0;36mgen_batch\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_captcha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mbatch_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;31m#rgb转为灰度值，再归一化\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mbatch_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#text变为one hot coding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\TF\\Pycharm\\Captcha.py\u001b[0m in \u001b[0;36mgen_captcha\u001b[1;34m(number)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageCaptcha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcaptcha_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_random_captcha_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mcaptcha_os\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptcha_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#captcha_os为一个jpg的输出流\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mcaptcha_image\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptcha_os\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#PIL中的open函数允许把输出流转换为jpg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mcaptcha_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptcha_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#np.array允许把输出流转为像素值矩阵\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\captcha\\image.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, chars, format)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \"\"\"\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\captcha\\image.py\u001b[0m in \u001b[0;36mgenerate_image\u001b[1;34m(self, chars)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_noise_dots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_noise_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImageFilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSMOOTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, filter)\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[0mmultiband\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultibandFilter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbands\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmultiband\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[0mims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\PIL\\ImageFilter.py\u001b[0m in \u001b[0;36mfilter\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"P\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot filter palette images\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(r'.\\Pycharm')\n",
    "from Captcha import gen_captcha,numbers\n",
    "\n",
    "def text2vec(text):#text变为one hot coding\n",
    "    vector = np.zeros(40)\n",
    "    for i in range(len(text)):\n",
    "        idx = i*10+ord(text[i])-48#ACSII转int\n",
    "        vector[idx] = 1\n",
    "    return vector\n",
    "\n",
    "def gen_batch(size=100):#生成一批数据\n",
    "    batch_x = np.zeros((size,9600))\n",
    "    batch_y = np.zeros((size,40))\n",
    "    for i in range(size):\n",
    "        text,image,data = gen_captcha()\n",
    "        batch_x[i,:] = np.mean(image,-1).flatten()/255#rgb转为灰度值，再归一化\n",
    "        batch_y[i,:] = text2vec(text)#text变为one hot coding\n",
    "    return batch_x,batch_y\n",
    "    \n",
    "with tf.name_scope('input') as scope:#name_scope可以让变量有相同的命名，只是限于tf.Variable的变量，可以看做程序里的一个单元\n",
    "    x = tf.placeholder(tf.float32,[None,60*160],name='x')#N张图片，每张图片像素60*160，放入灰度图\n",
    "    y_ = tf.placeholder(tf.float32,[None,4*10],name='y_')#one hot coding 6;[0,0,0,0,0,0,1,0,0,0],每个y_ 4个数字，每个数字用1*10向量表示\n",
    "    \n",
    "with tf.name_scope('net') as scope:\n",
    "    x_ = tf.reshape(x,shape=[-1,60,160,1])\n",
    "    #卷积神经网络\n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        w_c1 = tf.Variable(0.01*tf.random_normal([3,3,1,1]))#*0.01因为不乘的话数字太大，收敛慢\n",
    "        #w_c1 = tf.Variable(0.01*tf.random_normal([3,3,1,32]))\n",
    "        b_c1 = tf.Variable(0.1*tf.random_normal([1]))\n",
    "        #b_c1 = tf.Variable(0.1*tf.random_normal([32]))\n",
    "        #卷积\n",
    "        conv1 = tf.nn.conv2d(x_,w_c1,strides=[1,1,1,1],padding='SAME')\n",
    "        image = tf.reshape(conv1,shape=[-1,60,160,1])\n",
    "        tf.summary.image('image1-1',image)\n",
    "        #激活\n",
    "        conv1 = tf.nn.relu(tf.nn.bias_add(conv1,b_c1))\n",
    "        image = tf.reshape(conv1,shape=[-1,60,160,1])\n",
    "        tf.summary.image('image1-2',image)\n",
    "        #池化\n",
    "        conv1 = tf.nn.max_pool(conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "        image = tf.reshape(conv1,shape=[-1,30,80,1])\n",
    "        tf.summary.image('image1-3',image)\n",
    "     #Dense\n",
    "    with tf.name_scope('dense') as scope:\n",
    "        w_d  = tf.Variable(tf.random_normal([30*80,1024]))\n",
    "        #w_d  = tf.Variable(tf.random_normal([32*30*80,1024]))\n",
    "        b_d = tf.Variable(tf.random_normal([1024]))\n",
    "        dense = tf.reshape(conv1,[-1,w_d.get_shape().as_list()[0]])\n",
    "        dense = tf.nn.relu(tf.add(tf.matmul(dense,w_d),b_d))\n",
    "        dense = tf.nn.dropout(dense, 0.75)\n",
    "    #输出\n",
    "    with tf.name_scope('output') as scope:\n",
    "        w = tf.Variable(0.01*tf.random_normal([1024,40]),name = 'w')\n",
    "        b = tf.Variable(0.1*tf.random_normal([40]),name = 'b')\n",
    "        y = tf.matmul(dense,w)+b\n",
    "    \n",
    "with tf.name_scope('training') as scope:\n",
    "    #loss = tf.losses.mean_squared_error(y_, y)\n",
    "    loss = tf.losses.sigmoid_cross_entropy(y_,y)\n",
    "    tf.summary.scalar('loss',loss)#记录并统计loss\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "    \n",
    "with tf.name_scope('predict') as scope:\n",
    "    p = tf.argmax(tf.reshape(y,[-1,4,10]),2) #在第二个维度将one hot coding转为十进制数，投票的方式\n",
    "    label = tf.argmax(tf.reshape(y_,[-1,4,10]),2)\n",
    "    pred = tf.equal(p,label)#判断预测和真实值是否相等\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred,tf.float32))\n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    " \n",
    "       \n",
    "with tf.Session() as sess:\n",
    "    merged = tf.summary.merge_all()    \n",
    "    tf.global_variables_initializer().run()\n",
    "    writer = tf.summary.FileWriter('./log/demo18',sess.graph)\n",
    "    \n",
    "    \n",
    "    step=0\n",
    "    for i in range(5000):\n",
    "        #训练\n",
    "        x_train,y_train = gen_batch(64)\n",
    "        _,loss_ = sess.run([optimizer,loss],feed_dict={x:x_train,y_:y_train})\n",
    "        print(step,loss_)\n",
    "        #每100批测试一次准确率\n",
    "        if step%50 == 0:\n",
    "            x_test,y_test = gen_batch(50)\n",
    "            #acc = sess.run([accuracy], feed_dict={x:x_test, y_:y_test})\n",
    "            summary,acc = sess.run([merged,accuracy],feed_dict={x:x_test,y_:y_test})\n",
    "            writer.add_summary(summary,step)\n",
    "            print(acc)\n",
    "        step = step + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
